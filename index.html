<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Guanghui Wang Gatech</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Guanghui Wang</h1>
        <img src="me5.png">
        <p>PhD Student in Machine Learning<br/>School of Computer Science<br/>Georgia Institute of Technology<br/>Office: CODA 12th Floor S1249J</p>
        <p><a href="https://scholar.google.com/citations?user=oNgvRg4AAAAJ&hl=en">Google Scholar</a> | <a href="https://twitter.com/__waaagh__">Twitter</a> </p>
      
        
      </header>
      <section>
        <h2>About Me</h2>
        <p>Hello! I am Guanghui Wang (王广辉), a second-year PhD student in <a href="https://ml.gatech.edu/">Machine Learning</a> at <a href="https://www.gatech.edu/">Georgia Institute of Technology</a>. I am very fortunate to be advised by Prof. <a href="https://faculty.cc.gatech.edu/~jabernethy9/">Jake Abernethy</a> and Prof. <a href="https://vmuthukumar.ece.gatech.edu/">Vidya Muthukumar</a>.</p>
        
        
        <p>Before joining Georgia Tech, I obtained my M.S. degree from <a href="https://www.nju.edu.cn/EN/7f/6b/c7136a163691/page.htm">Department of Computer Science and Technology</a> in <a href="https://www.nju.edu.cn/EN/main.htm">Nanjing University</a> in 2020, where I was very fortunate to be advised by Prof. <a href="https://cs.nju.edu.cn/zlj/index.htm">Lijun Zhang</a>. I was also a member of the <a href="http://www.lamda.nju.edu.cn/MainPage.ashx">LAMDA</a> group, led by Prof. <a href="https://cs.nju.edu.cn/zhouzh/index.htm">Zhi-Hua Zhou</a>. I received my B.E. degree from <a href="http://english.ee.xidian.edu.cn/">School of Electronic Engineering</a> in <a href="https://en.xidian.edu.cn/index.htm">Xidian University</a> in 2017.</p>

        <p>I am interested in online learning, stochastic optimization, and game theory.</p>


        <h2>Publications</h2>
        <h3>Preprints</h3>
        <ol>
            <li><a href="https://arxiv.org/abs/2305.17544"> Faster Margin Maximization Rates for Generic Optimization Methods</a> <br>
            <b>Guanghui Wang</b>, Zihao Hu, Vidya Muthukumar, Jacob Abernethy.<br>
            In submission.  
              <li><a href="https://arxiv.org/abs/2305.19349"> On Riemannian Projection-free Online Learning</a> <br>
            Zihao Hu, <b>Guanghui Wang</b>, Jacob Abernethy.<br>
            In submission.  
        </ol>
        <h3>Conference Papers</h3>
        <ol>
            <li><a href="https://arxiv.org/abs/2302.08652">Minimizing Dynamic Regret on Geodesic Metric Spaces</a><br>
            Zihao Hu, <b>Guanghui Wang</b>, Jacob Abernethy.<br>
            COLT2023. To appear.   
          <li> <a href="https://arxiv.org/abs/2210.09371">On Accelerated Perceptrons and Beyond</a><br>
         <b>Guanghui Wang</b>, Rafael Hanashiro, Etash Guha, Jacob Abernethy. <br>
         ICLR 2023.</li>
         <li> <a href="https://arxiv.org/abs/2210.09385"> Adaptive Oracle-Efficient Online Learning</a><br>
         <b>Guanghui Wang</b>, Zihao Hu, Vidya Muthukumar, Jacob Abernethy. <br>
         NeurIPS 2022.</li>
        <li> <a href="https://proceedings.mlr.press/v162/zhang22af/zhang22af.pdf">A Simple yet Universal Strategy for Online Convex Optimization</a><br>
         Lijun Zhang, <b>Guanghui Wang</b>, Jinfeng Yi, Tianbao Yang.<br>    
          ICML 2022. </li>
         <li> <a href="https://proceedings.mlr.press/v151/wang22b/wang22b.pdf">Momentum Accelerates the Convergence of Stochastic AUPRC Maximization</a><br>
         <b>Guanghui Wang</b>, Ming Yang, Lijun Zhang, Tianbao Yang. <br>
         AISTATS 2022. </li>
         <li> <a href="https://proceedings.neurips.cc/paper/2021/file/f08b7ac8aa30a2a9ab34394e200e1a71-Paper.pdf">Online Convex Optimization with Continuous Switching Constraint</a><br>
         <b>Guanghui Wang</b>, Yuanyu Wan, Tianbao Yang, Lijun Zhang <br>
         NeurIPS 2021. </li>
              <li> <a href="https://proceedings.neurips.cc/paper/2021/file/d1588e685562af341ff2448de4b674d1-Paper.pdf">Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive Regret of Convex Functions</a><br>
         Lijun Zhang, <b>Guanghui Wang</b>, Wei-Wei Tu, Wei Jiang, Zhi-Hua Zhou. <br>
         NeurIPS 2021. </li>
                <li> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17060">Stochastic Graphical Bandits with Adversarial Corruptions</a><br>
         Shiyin Lu, <b>Guanghui Wang</b>, Lijun Zhang. <br>
         AAAI 2021. </li>
         
                      <li> <a href="https://openreview.net/pdf?id=rye5YaEtPr">Sadam: A Variant of Adam for Strongly Convex Functions</a><br>
         <b>Guanghui Wang</b>, Shiyin Lu, Quan Cheng, Wei-Wei Tu, Lijun Zhang. <br>
         ICLR 2020. </li>
           <li> <a href="http://129.211.169.156/publication/aistats20bco.pdf">Bandit Convex Optimization in Non-stationary Environments.</a><br>
         Peng Zhao, <b>Guanghui Wang</b>, Lijun Zhang, Zhi-Hua Zhou. <br>
         AISTATS 2020. </li>
         
                         <li> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6081">Adapting to Smoothness: A More Universal Algorithm for Online Convex Optimization</a><br>
         <b>Guanghui Wang</b>, Shiyin Lu, Yao Hu, Lijun Zhang. <br>
         AAAI 2020. </li>
          <li> <a href="https://www.ijcai.org/Proceedings/2020/0406.pdf">Nearly Optimal Regret for Stochastic Linear Bandits with Heavy-Tailed Payoffs</a><br>
         Bo Xue, <b>Guanghui Wang</b>, Yimu Wang, Lijun Zhang. <br>
         IJCAI 2020. </li>
         
             <li> <a href="http://proceedings.mlr.press/v115/wang20e/wang20e.pdf">Adaptivity and Optimality: A Universal Algorithm for Online Convex Optimization</a><br>
         <b>Guanghui Wang</b>, Shiyin Lu, Lijun Zhang. <br>
         UAI 2019. </li>
         
          <li> <a href="http://www.lamda.nju.edu.cn/lusy/pdf/lu2019multi.pdf">Multi-Objective Generalized Linear Bandits</a><br>
         Shiyin Lu, <b>Guanghui Wang</b>, Yao Hu, Lijun Zhang. <br>
         IJCAI 2019. </li>
                   <li> <a href="http://proceedings.mlr.press/v97/lu19c/lu19c.pdf">Optimal Algorithms for Lipschitz Bandits with Heavy-Tailed Rewards</a><br>
         Shiyin Lu, <b>Guanghui Wang</b>, Yao Hu, Lijun Zhang. <br>
         ICML 2019. </li>
            <li> <a href="https://www.ijcai.org/proceedings/2018/0383.pdf">Minimizing Adaptive Regret with One Gradient per Iteration</a><br>
         <b>Guanghui Wang</b>, Dakuan Zhao, Lijun Zhang. <br>
         IJCAI 2018. </li>
        </ol>
        <h3>Journal Articles</h3>
        <ol>
           <li> <a href="https://yuanyuwan.github.io/pdf/JMLR-2022-Wan.pdf">Projection-free Distributed Online Learning with Sublinear Communication Complexity</a><br>
         Yuanyu Wan, <b>Guanghui Wang</b>, Wei-Wei Tu, Lijun Zhang. <br>
        JMLR 2022. </li>
        
              <li> <a href="http://www.lamda.nju.edu.cn/zhaop/publication/JMLR'21_BCO.pdf">Bandit Convex Optimization in Non-stationary Environments</a><br>
         Peng Zhao, <b>Guanghui Wang</b>, Lijun Zhang, Zhi-Hua Zhou. <br>
        JMLR 2021. </li>
         
                 </ol>
            <h2>Academic Service</h2>     
            <p> Reviewer: ICML, ICLR, NeurIPS, AISTATS, TMLR
            <h2>Working\Visiting Experience</h2>
            <ol>
            <li> <a href="https://simons.berkeley.edu/people/guanghui-wang">Visiting Graduate Student</a>, Spring 2021, Simons Institute for the Theory of Computing.</li>
              <li>  Reseach Assistant, Fall 2020 - Fall 2021, Nanjing University.</li>    
               </ol>
            <h2>Awards</h2>
            <ol>
            <li>ARC-ACO Fellowship, 2022.</li>
              <li>National Scholarship, 2014, 2018.</li>
               </ol>
 <h2> </h2>           
<p><a href="https://clustrmaps.com/site/1br77" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=oIMtFWyEbifgZqnyOLd8DpuPcI-XMsIMv5l0w94TBQI&cl=ffffff"></a>
            </section>

      <footer>
        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>


  </body>
</html>